# INTRODUCE FOR LINEAR ALGEBRA

## 1. Data Structures For Linear Algebra

### Tensor

### Scalar

L√† m·ªôt s·ªë ƒë∆°n l·∫ª v√† kh√¥ng c√≥ chi·ªÅu
  
``` bash
# Scalar
scalar_number = tourch.tensor(25)
```

### Vector

L√† m·∫£ng m·ªôt chi·ªÅu c·ªßa c√°c s·ªë

``` bash
# Vector
vector1 = numpy.array([1,2,3])

# Vector Matrix
vector2 = numpy.array([[1,2,3]])

# Vector Transposition (0,3) to (3,0)
vector_t1 = vector1.T

# Vector Transposition (1,3) to (3,1)
vector_t2 = vector2.T

# Vector in Pytorch and Tensorflow
vector = tourch.tensor([1,2,3])
```

### Norms

- Norms l√† m·ªôt l·ªõp h√†m cho ph√©p ta ƒë·ªãnh l∆∞·ª£ng ƒë·ªô d√†i c·ªßa 1 vector cho tr∆∞·ªõc
- L2 Norm hay c√≤n g·ªçi l√† Kho·∫£ng c√°ch Euclid l√† ph∆∞∆°ng ph√°p quan tr·ªçng v√† ph·ªï bi·∫øn nh·∫•t
- Unit Vector l√† m·ªôt vector c√≥ ƒë·ªô d√†i b·∫±ng 1

![image](https://github.com/tuanng1102/math-for-machine-learning/assets/147653892/0aacaf0c-ad32-4fe5-999e-e34481bee8e7)

``` bash
# Calculate L2 Norm
x = np.array([25, 2, 5])
np.linalg.norm(x)
```

### Matrix
- Ma tr·∫≠n l√† m·ªôt m·∫£ng 2 chi·ªÅu c·ªßa c√°c s·ªë
- Vi·∫øt d∆∞·ªõi d·∫°ng (m * n)

``` bash
# Create a matrix (3,2)
X = np.array([[1,2],[4,5],[7,8]])

# Create a matrix in Pytourch and Tensorflow
X = tourch.tensor([[1,2],[4,5],[7,8]])

# Create a zeros matrix image in Pytorch with 28*28 size, 32 images, 3 chanels
image_pt = tourch.zeros([32,28,28,3])
```

## 2. Tensor Operations
### Tensor Transposition
- Chuy·ªÉn v·ªã c·ªßa Scalar l√† ch√≠nh n√≥
- Chuy·ªÉn v·ªã c·ªßa Vector v√† Matrix l√† chuy·ªÉn ƒë·ªïi gi·ªØa h√†ng v√† c·ªôt

``` bash
# Create a matrix (3,2)
X = np.array([[1,2],[4,5],[7,8]])

# Matrix Transposition
X.T
```
### Tensor Calculation
T√≠ch c·ªßa Tensor v·ªõi m·ªôt s·ªë b·∫±ng t√≠ch c·ªßa s·ªë ƒë√≥ v·ªõi t·∫•t c·∫£ c√°c s·ªë trong Tensor

``` bash
# T√≠ch Tensor v·ªõi 1 s·ªë
X * 2
```

T·ªïng c·ªßa Tensor v·ªõi 1 s·ªë b·∫±ng t·ªïng c·ªßa s·ªë ƒë√≥ v·ªõi t·∫•t c·∫£ c√°c s·ªë trong Tensor
``` bash
# T·ªïng Tensor v·ªõi 1 s·ªë
X + 2
```

T·ªïng c·ªßa 2 Tensor c√πng chi·ªÅu l√† t·ªïng c·ªßa t·ª´ng ph·∫ßn t·ª≠ trong Tensor n√†y v·ªõi Tensor c√≤n l·∫°i
``` bash
# T·ªïng Tensor v·ªõi Tensor
X + Y
```

T·ªïng c·ªßa t·∫•t c·∫£ c√°c ph·∫ßn t·ª≠ trong Tensor (min, max, mean)
``` bash
# T·ªïng c·ªßa t·∫•t c·∫£ c√°c ph·∫ßn t·ª≠ trong Tensor - Numpy
X.sum()

# T·ªïng c·ªßa t·∫•t c·∫£ c√°c ph·∫ßn t·ª≠ trong Tensor - Pytorch
tourch.sum(X)
```

T·ªïng c·ªßa t·∫•t c·∫£ c√°c ph·∫ßn t·ª≠ trong Tensor tr√™n 1 h√†ng v√† 1 c·ªôt (min, max, mean)
``` bash
# T·ªïng c·ªßa t·∫•t c·∫£ c√°c ph·∫ßn t·ª≠ trong Tensor tr√™n 1 h√†ng - Numpy
X.sum(axis=0)

# T·ªïng c·ªßa t·∫•t c·∫£ c√°c ph·∫ßn t·ª≠ trong Tensor tr√™n 1 c·ªôt- Numpy
X.sum(axis=1)

# T·ªïng c·ªßa t·∫•t c·∫£ c√°c ph·∫ßn t·ª≠ trong Tensor tr√™n 1 h√†ng - Pytorch
tourch.sum(X, 0)

# T·ªïng c·ªßa t·∫•t c·∫£ c√°c ph·∫ßn t·ª≠ trong Tensor tr√™n 1 c·ªôt- Pytorch
tourch.sum(X, 1)
```

### Hadamard Product
L√† t√≠ch c·ªßa 2 Matrix c√πng chi·ªÅu b·∫±ng c√°ch nh√¢n t·ª´ng ph·∫ßn t·ª≠ c·ªßa ma tr·∫≠n n√†y t∆∞∆°ng ·ª©ng v·ªõi t·ª´ng ph·∫ßn t·ª≠ c·ªßa ma tr·∫≠n kia

``` bash
# Hadamard product
X * Y
```

### Dot Product
T√≠ch v√¥ h∆∞·ªõng c·ªßa 2 Vector l√† t√≠ch c·ªßa Vector A v·ªõi Vector B
``` bash
# Dot product
np.dot(X,Y)
```

### Substitution and Elimination

![image](https://github.com/tuanng1102/math-for-machine-learning/assets/147653892/a978d4e2-e4d1-4515-92c0-ec9cbda90844)

## 3. Matrix Propeties

### Frobenius Norm

B·∫±ng cƒÉn b·∫≠c 2 c·ªßa t·ªïng t·∫•t c·∫£ c√°c ph·∫ßn t·ª≠ b√¨nh ph∆∞∆°ng trong ma tr·∫≠n

![image](https://github.com/tuanng1102/math-for-machine-learning/assets/147653892/eafb5f19-3d9d-4b21-8013-4beb9a8b92f8)

``` bash
# Calculate Frobenius Norm
x = np.array([25, 2, 5],[1,2,4],[4,12,11])
np.linalg.norm(x)
```

### Matrix Multiplication

Matrix v·ªõi Vector

![image](https://github.com/tuanng1102/math-for-machine-learning/assets/147653892/1ff2c3ce-c8c6-4ded-99a0-002c2331e504)

``` bash
# Matrix v·ªõi Vector
np.dot(A,B)
```

Matrix v·ªõi Matrix

![image](https://github.com/tuanng1102/math-for-machine-learning/assets/147653892/a61cf4fb-a4b0-4bcd-8604-18b6a3d95369)

``` bash
# Matrix v·ªõi Matrix
np.dot(A,B)
```

### Symmetric Matrix

Ma tr·∫≠n ƒë·ªëi x·ª©ng l√† ma tr·∫≠n m√† chuy·ªÉn v·ªã c·ªßa n√≥ b·∫±ng ch√≠nh n√≥

![image](https://github.com/tuanng1102/math-for-machine-learning/assets/147653892/0f9b1de2-1c6a-4c04-a002-411d273d7a29)

### Identity Matrix

Ma tr·∫≠n ƒë∆°n v·ªã l√† m·ªôt lo·∫°i ma tr·∫≠n vu√¥ng trong ƒë√≥ t·∫•t c·∫£ c√°c ph·∫ßn t·ª≠ tr√™n ƒë∆∞·ªùng ch√©o ch√≠nh (t·ª´ g√≥c tr√™n b√™n tr√°i ƒë·∫øn g√≥c d∆∞·ªõi b√™n ph·∫£i) ƒë·ªÅu c√≥ gi√° tr·ªã b·∫±ng 1, v√† t·∫•t c·∫£ c√°c ph·∫ßn t·ª≠ c√≤n l·∫°i ƒë·ªÅu b·∫±ng 0.

![image](https://github.com/tuanng1102/math-for-machine-learning/assets/147653892/71dc6121-594d-4cf8-bb17-bd2aef510165)

### Matrix Inversion

Ma tr·∫≠n ngh·ªãch ƒë·∫£o c·ªßa m·ªôt ma tr·∫≠n vu√¥ng ùê¥ l√† m·ªôt ma tr·∫≠n sao cho t√≠ch c·ªßa n√≥ v·ªõi ma tr·∫≠n ban ƒë·∫ßu l√† ma tr·∫≠n ƒë∆°n v·ªã v√† t√≠ch c·ªßa ma tr·∫≠n ban ƒë·∫ßu v·ªõi ma tr·∫≠n ngh·ªãch ƒë·∫£o c≈©ng l√† ma tr·∫≠n ƒë∆°n v·ªã.

``` bash
# Ma tr·∫≠n ngh·ªãch ƒë·∫£o
X_inv = np.linalg.inv(X)
```

### Diagonal Matrix

Ma tr·∫≠n ƒë∆∞·ªùng ch√©o l√† m·ªôt lo·∫°i ma tr·∫≠n trong ƒë√≥ t·∫•t c·∫£ c√°c ph·∫ßn t·ª≠ n·∫±m ngo√†i ƒë∆∞·ªùng ch√©o ch√≠nhƒë·ªÅu b·∫±ng 0. C√°c ph·∫ßn t·ª≠ tr√™n ƒë∆∞·ªùng ch√©o ch√≠nh c√≥ th·ªÉ c√≥ gi√° tr·ªã kh√°c nhau.

![image](https://github.com/tuanng1102/math-for-machine-learning/assets/147653892/49a594b5-1492-489a-95dc-8e5cd2e7d205)

### Orthofonal Matrix

Ma tr·∫≠n tr·ª±c giao l√† m·ªôt ma tr·∫≠n vu√¥ng m√† t√≠ch c·ªßa n√≥ v·ªõi chuy·ªÉn v·ªã c·ªßa n√≥ l√† ma tr·∫≠n ƒë∆°n v·ªã.

![image](https://github.com/tuanng1102/math-for-machine-learning/assets/147653892/5f3965bb-c980-4477-ae5c-e0da5a72b973)
